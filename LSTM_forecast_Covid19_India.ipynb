{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>1024</td>\n",
       "      <td>27</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>1251</td>\n",
       "      <td>32</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>1397</td>\n",
       "      <td>35</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>1998</td>\n",
       "      <td>58</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>2543</td>\n",
       "      <td>72</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cases  Deaths  Recovered\n",
       "Date                                \n",
       "2020-03-29   1024      27         95\n",
       "2020-03-30   1251      32        102\n",
       "2020-03-31   1397      35        123\n",
       "2020-04-01   1998      58        148\n",
       "2020-04-02   2543      72        191"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input sequence\n",
    "series = pd.read_csv(r\"C:\\Users\\IFMRUSER\\Desktop\\Deep Learning\\India_covid19.csv\", index_col = 'Date' , parse_dates = True)\n",
    "#taking the dataset when India crossed 1000 mark \n",
    "dataset=series.iloc[67:]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-81.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>455.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>-56.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>-521.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-04</th>\n",
       "      <td>491.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cases  Deaths  Recovered\n",
       "Date                                \n",
       "2020-03-31  -81.0    -2.0       14.0\n",
       "2020-04-01  455.0    20.0        4.0\n",
       "2020-04-02  -56.0    -9.0       18.0\n",
       "2020-04-03 -521.0   -14.0      -42.0\n",
       "2020-04-04  491.0    14.0       36.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd order difference for Stationarty (derived from auto_arima() - see VARMA model)\n",
    "dataset_transformed = dataset.diff().diff()\n",
    "dataset_transformed = dataset_transformed.dropna()\n",
    "dataset_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "(0, 3)\n",
      "(49, 3)\n"
     ]
    }
   ],
   "source": [
    "# move entire data to test\n",
    "print(len(dataset_transformed))\n",
    "nobs=0\n",
    "train = dataset_transformed.iloc[:-nobs]\n",
    "test = dataset_transformed.iloc[-nobs:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normaliznig the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test)\n",
    "#scaled_train =  scaler.transform(train)\n",
    "scaled_test =  scaler.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the inputs for LSTM model\n",
    "n_input = 3\n",
    "n_features = 3\n",
    "n_neurons = 100\n",
    "\n",
    "\n",
    "train_generator = TimeseriesGenerator(scaled_test, scaled_test, length = n_input, batch_size = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the vanilla LSTM model (this is post few hyperparameters tuning )\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, activation = 'relu', input_shape = (n_input, n_features), recurrent_dropout = 0.45))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 4s 11ms/step - loss: 0.0391\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0227\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0186\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0168\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0155\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0144\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0138\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0127\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0120\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0112\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0101\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0100\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0094\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0092\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0086\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0081\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0074\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0073\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0067\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0065\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0065\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0059\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0054\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0054\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0050\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0050\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0046\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0046\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0044\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0043\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0042\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0039\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0038\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0036\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0034\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0034\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0036\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0033\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0031\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0031\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0030\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0029\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0027\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0028\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0025\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0027\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0027\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0025\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0025\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0022\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0022\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0021\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0021\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0021\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0021\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0021\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0020\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0019\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0019\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0018\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0018\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0018\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0018\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0018\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0016\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0015\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0015\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0015\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0015\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0016\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0016\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0014\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0016\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0012\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0014A: 0s - loss: 0.\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0013\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0012\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0012A: 1s - loss: \n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0011\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0011\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.001 - 4s 9ms/step - loss: 0.0011\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0013\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0011\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0011\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 0.0011: 1s - loss: 0.00\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0012\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.5214e-04\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.4318e-04\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.3321e-04\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.1486e-04\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.7308e-04\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 0.0010\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.6449e-04\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.7842e-04\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 9.0411e-04\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.2668e-04\n",
      "Epoch 108/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.6170e-04\n",
      "Epoch 109/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.8814e-04A\n",
      "Epoch 110/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.3712e-04\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.8803e-04\n",
      "Epoch 112/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 8.7548e-04\n",
      "Epoch 113/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.1664e-04\n",
      "Epoch 114/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.8758e-04\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.9007e-04\n",
      "Epoch 116/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.5994e-04\n",
      "Epoch 117/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.1684e-04\n",
      "Epoch 118/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.1852e-04\n",
      "Epoch 119/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.2011e-04\n",
      "Epoch 120/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.7756e-04\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.2471e-04\n",
      "Epoch 122/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.7494e-04A\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.4522e-04\n",
      "Epoch 124/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 7.5629e-04\n",
      "Epoch 125/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.4002e-04\n",
      "Epoch 126/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.8012e-04\n",
      "Epoch 127/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.7709e-04\n",
      "Epoch 128/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.4063e-04\n",
      "Epoch 129/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.5025e-04\n",
      "Epoch 130/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.9191e-04\n",
      "Epoch 131/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.8856e-04\n",
      "Epoch 132/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.7600e-04\n",
      "Epoch 133/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.9015e-04\n",
      "Epoch 134/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.5305e-04\n",
      "Epoch 135/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.3277e-04\n",
      "Epoch 136/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.3456e-04\n",
      "Epoch 137/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.3554e-04\n",
      "Epoch 138/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.6987e-04\n",
      "Epoch 139/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.4613e-04\n",
      "Epoch 140/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.1573e-04\n",
      "Epoch 141/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.5834e-04\n",
      "Epoch 142/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 6.8909e-04\n",
      "Epoch 143/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 5.9661e-04\n",
      "Epoch 144/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.5141e-04\n",
      "Epoch 145/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.9102e-04\n",
      "Epoch 146/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.4282e-04\n",
      "Epoch 147/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.5780e-04\n",
      "Epoch 148/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.4374e-04\n",
      "Epoch 149/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.8285e-04\n",
      "Epoch 150/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.3304e-04\n",
      "Epoch 151/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.3145e-04\n",
      "Epoch 152/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.3863e-04\n",
      "Epoch 153/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.8866e-04\n",
      "Epoch 154/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.8180e-04\n",
      "Epoch 155/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.9437e-04\n",
      "Epoch 156/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.2378e-04\n",
      "Epoch 157/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 5.8236e-04\n",
      "Epoch 158/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.7215e-04\n",
      "Epoch 159/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.7689e-04\n",
      "Epoch 160/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.8624e-04\n",
      "Epoch 161/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 5.1267e-04: 2s - loss: - E - ETA: 0s - loss: 5\n",
      "Epoch 162/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.4619e-04\n",
      "Epoch 163/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.4339e-04\n",
      "Epoch 164/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.5234e-04\n",
      "Epoch 165/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.5424e-04\n",
      "Epoch 166/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 5.0825e-04\n",
      "Epoch 167/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.0456e-04\n",
      "Epoch 168/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.7716e-04\n",
      "Epoch 169/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.6057e-04\n",
      "Epoch 170/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.3469e-04\n",
      "Epoch 171/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.8893e-04\n",
      "Epoch 172/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.0219e-04\n",
      "Epoch 173/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.5312e-04\n",
      "Epoch 174/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 4.3670e-04: 0s - lo\n",
      "Epoch 175/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.1749e-04\n",
      "Epoch 176/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.5476e-04\n",
      "Epoch 177/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.1852e-04\n",
      "Epoch 178/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 4.3925e-04\n",
      "Epoch 179/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.1100e-04\n",
      "Epoch 180/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.1492e-04\n",
      "Epoch 181/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.9959e-04\n",
      "Epoch 182/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.2356e-04\n",
      "Epoch 183/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8992e-04\n",
      "Epoch 184/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8743e-04\n",
      "Epoch 185/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.5564e-04\n",
      "Epoch 186/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8369e-04\n",
      "Epoch 187/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.9293e-04\n",
      "Epoch 188/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 3.5103e-04\n",
      "Epoch 189/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.7695e-04\n",
      "Epoch 190/200\n",
      "400/400 [==============================] - 4s 10ms/step - loss: 3.4712e-04\n",
      "Epoch 191/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8114e-04\n",
      "Epoch 192/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8120e-04\n",
      "Epoch 193/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.6480e-04\n",
      "Epoch 194/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.9264e-04\n",
      "Epoch 195/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.6360e-04\n",
      "Epoch 196/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.6355e-04\n",
      "Epoch 197/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.5313e-04\n",
      "Epoch 198/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 4.2827e-04\n",
      "Epoch 199/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.7413e-04\n",
      "Epoch 200/200\n",
      "400/400 [==============================] - 4s 9ms/step - loss: 3.8424e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x142324c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fittng the model (this is post few hyperparameters tuning )\n",
    "model.fit_generator(train_generator, epochs = 200, steps_per_epoch=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test[-3:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting using the tuned model\n",
    "test_predictions = []\n",
    "first_eval_batch = scaled_test[-3:]\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(7):\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    test_predictions.append(current_pred)\n",
    "    \n",
    "    current_batch = np.append(current_batch[:,1:,:], [[current_pred]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  837.28395778,    76.89424527,   151.92095947],\n",
       "       [-1897.36312267,   -47.65207443,   262.75561523],\n",
       "       [ 1537.30595231,   -62.28449303,  -480.60827637],\n",
       "       [ -555.90938203,   -17.64234695,   233.92785645],\n",
       "       [  227.62084222,    13.1944215 ,   -14.38705444],\n",
       "       [  249.01430452,   -46.73232752,  1588.8848877 ],\n",
       "       [ 2070.27705657,    99.09630281,    10.87957764]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inversing the normalized values \n",
    "true_predictions = scaler.inverse_transform(test_predictions)\n",
    "true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      A          B            C\n",
      "2020-05-19   837.283958  76.894245   151.920959\n",
      "2020-05-20 -1897.363123 -47.652074   262.755615\n",
      "2020-05-21  1537.305952 -62.284493  -480.608276\n",
      "2020-05-22  -555.909382 -17.642347   233.927856\n",
      "2020-05-23   227.620842  13.194421   -14.387054\n",
      "2020-05-24   249.014305 -46.732328  1588.884888\n",
      "2020-05-25  2070.277057  99.096303    10.879578\n"
     ]
    }
   ],
   "source": [
    "#Lets see the predictions (these are the predctions in 2nd order difference)\n",
    "df_cast = pd.DataFrame(true_predictions, columns=list('ABC'))\n",
    "df_cast.index = pd.date_range('5/19/2020', periods=7, freq='D')\n",
    "print(df_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversing the 2nd order difference\n",
    "\n",
    "# Add the most recent first difference from the training set to the forecast cumulative sum\n",
    "df_cast['Cases1d'] = (dataset['Cases'].iloc[-nobs-1]-dataset['Cases'].iloc[-nobs-2]) + df_cast['A'].cumsum()\n",
    "df_cast['Deaths1d'] = (dataset['Deaths'].iloc[-nobs-1]-dataset['Deaths'].iloc[-nobs-2]) + df_cast['B'].cumsum()\n",
    "df_cast['Recovered1d'] = (dataset['Recovered'].iloc[-nobs-1]-dataset['Recovered'].iloc[-nobs-2]) + df_cast['C'].cumsum()\n",
    "\n",
    "\n",
    "# Now build the forecast values from the first difference set\n",
    "df_cast['CasesForecast'] = dataset['Cases'].iloc[-nobs-1] + df_cast['Cases1d'].cumsum()\n",
    "df_cast['DeathsForecast'] = dataset['Deaths'].iloc[-nobs-1] + df_cast['Deaths1d'].cumsum()\n",
    "df_cast['RecoveredForecast'] = dataset['Recovered'].iloc[-nobs-1] + df_cast['Recovered1d'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CasesForecast</th>\n",
       "      <th>DeathsForecast</th>\n",
       "      <th>RecoveredForecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-19</th>\n",
       "      <td>105795.283958</td>\n",
       "      <td>3363.894245</td>\n",
       "      <td>41822.920959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-20</th>\n",
       "      <td>109365.204793</td>\n",
       "      <td>3524.136416</td>\n",
       "      <td>44675.597534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-21</th>\n",
       "      <td>114472.431580</td>\n",
       "      <td>3622.094094</td>\n",
       "      <td>47047.665833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-22</th>\n",
       "      <td>119023.748986</td>\n",
       "      <td>3702.409425</td>\n",
       "      <td>49653.661987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-23</th>\n",
       "      <td>123802.687233</td>\n",
       "      <td>3795.919177</td>\n",
       "      <td>52245.271088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>128830.639785</td>\n",
       "      <td>3842.696602</td>\n",
       "      <td>56425.765076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-25</th>\n",
       "      <td>135928.869394</td>\n",
       "      <td>3988.570330</td>\n",
       "      <td>60617.138641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CasesForecast  DeathsForecast  RecoveredForecast\n",
       "2020-05-19  105795.283958     3363.894245       41822.920959\n",
       "2020-05-20  109365.204793     3524.136416       44675.597534\n",
       "2020-05-21  114472.431580     3622.094094       47047.665833\n",
       "2020-05-22  119023.748986     3702.409425       49653.661987\n",
       "2020-05-23  123802.687233     3795.919177       52245.271088\n",
       "2020-05-24  128830.639785     3842.696602       56425.765076\n",
       "2020-05-25  135928.869394     3988.570330       60617.138641"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets now see the forecasted values for next week\n",
    "df_cast.iloc[:,6:9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
